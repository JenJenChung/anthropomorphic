<!DOCTYPE html>
<html>

    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Jen Jen Chung, UQ</title>
        <meta name="description" content="Jen Jen Chung, UQ">
        <meta name="author" content="Jen Jen Chung">
        <link rel="stylesheet" href="main.css">
        <link rel="shortcut icon" href="Logo/Derived/ICO/J2.ico">

        <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
        <script src="header_footer.js"></script>
    </head>
    <body class="idx">
    <img class="bg" alt="Dooralong" src="Gallery/Dooralong.jpg" />
    <div id="header"></div>
    
    <div class="page_content">

        <h1 align="left">
        Jen Jen Chung</h1>
        
        <p>
            I am an Associate Professor in the school of <a href="https://itee.uq.edu.au" target="_blank">Information Technology and Electrical Engineering</a> at The University of Queensland. <b>I'm just starting up my lab so watch this space for new developments and opportunities in the coming months!</b>
        </p>
        <p>
            Previously, I was a senior researcher at the <a href="https://asl.ethz.ch" target="_blank">Autonmous Systems Lab</a> in ETH Z&uuml;rich, I was a postdoc at the <a href="http://robotics.oregonstate.edu" target="_blank">Collaborative Robotics and Intelligent Systems Institute</a> in Oregon State University and prior to all of that I completed my PhD at the <a href="http://www.acfr.usyd.edu.au" target="_blank">Australian Centre for Field Robotics</a> in the University of Sydney<a href="#fn1" id="r1">*</a>.
        </p>
        <p>
            See below for the latest <a href="#news">news</a> and a list of my <a href="#projects">current and past research projects</a>.
        </p>
        
        <section id="news">
        <h2 align="left">News</h2>
        <details open="open">
          <summary>2022</summary>
          <ul>
              <li><b>CONGRATULATIONS</b> to our very latest <a href="https://www.linkedin.com/in/michel-breyer-384729141/" target="_blank"><b>Dr. Michel Breyer</b></a>! ASL's expert in robot grasping, check out his work on <a href="gallery.html#Breyer2020CORL"><b>VGN</b></a> and <a href="gallery.html#Breyer2022IROS"><b>active grasping</b></a>
              <li>At ISRR we asked the question: "How do we get robots to understand the world the way we do?" Check out our blue-sky paper <a href="publications.html#Chung2022semantics"><b>here</b></a>!</li>
              <li><b>CONGRATULATIONS</b> to our most newly minted <a href="https://www.linkedin.com/in/rikba/" target="_blank"><b>Dr. Rik B&auml;hnemann</b></a>, <a href="https://www.linkedin.com/in/daniel-dugas-bb0949122/" target="_blank"><b>Dr. Daniel Dugas</b></a>, and <a href="https://www.linkedin.com/in/florian-achermann-075924b2/" target="_blank"><b>Dr. Florian Achermann</b></a>! Extremely well done and well deserved!</li>
              <li>Our TRO paper on predicting multi-robot communication connectivity for active planning is now available in Early Access! You can also check it out <a href="publications.html#Zhang2022probabilistic"><b>here</b></a>!</li>
              <li>IROS papers, videos and code now available on <a href="publications.html#Breyer2022"><b>active grasping</b></a>, <a href="publications.html#Dugas2022navdreams"><b>world-models for vision-only navigation</b></a> and <a href="publications.html#Dugas2022flowbot"><b>flow-based crowd navigation</b></a>.</li>
              <li>New papers now available!</li>
              <ul>
                  <li>How to detect landmines from a drone (also including solutions for <i>micro</i>second time synchronization!) <a href="publications.html#Baehnemann2022">[<b>to the paper</b>]</a></li>
                  <li>Fast generation of keypoint annotation datasets <a href="publications.html#Blomqvist2022">[<b>to the paper</b>]</a> <a href="https://github.com/ethz-asl/object_keypoints" target="_blank">[<b>try it yourself</b>]</a></li>
              </ul>
              <li>Thanks <a href="https://www.ascento.ch/" target="_blank"><b>Ascento</b></a> for inviting me to give a keynote at your women*'s evening!</li>
<!--              <iframe src="https://www.linkedin.com/embed/feed/update/urn:li:share:6932716918571216897" allowfullscreen="" title="Embedded post" width="720" height="240" frameborder="0"></iframe>-->
              <li>Harmony integration week: <a href="https://harmony-eu.org/harmony-integration-week-april-2022/" target="_blank"><b>Two locations, two robots, one week to kick off our integration efforts!</b></a></li>
          </ul>
          </details>
        <details>
          <summary>2021</summary>
          <ul>
              <li>Discovered today that the top four most cited papers on my Google Scholar page are all first-authored by women!
              <img src="Home/gs_top_cited.png" height="256" hspace="10"/>
              <p>Go and find out more about each of my amazing co-authors: <a href="https://margaritagrinvald.com", target="_blank"><b>Margarita Grinvald</b></a>, <a href="https://aida-rahmattalabi.github.io" target="_blank"><b>Aida Rahmattalabi</b></a>, <a href="http://mashapopovic.com" target="_blank"><b>Marija Popovi&cacute;</b></a></p></li>
              <li><a href="https://harmony-eu.org" target="_blank"><b>Harmony has a brand new website</b></a> complete with more information on the project, the partners as well as the latest news and publications.</li>
              <li>Check out the great collaboration between our MAV and MoMa team in our Amazon Research Award project on <a href="gallery.html#Bodie2021ARA"><b>Omnidirectional Aerial Manipulation</b></a>! Also find out about the spin off student focus project <a href="https://www.griffin.ethz.ch" target="_blank"><b>Griffin</b></a> who built, tested and flew their own aerial manipulation platform in just 8 months!</li>
              <li>If you hate having to maually check the quality of your stereo camera calibration, check out our paper <a href="publications.html#Zhong2021"><b>CalQNet</b></a> which will be presented at IV2021!
              <li>We have six papers accepted to ICRA (including one accepted to RAL)! Links to papers and code in the <a href="publications.html"><b>publications</b></a> tab.</li>
              <li>We're kicking off a wonderful new EU H2020 project on mobile manipulation robots for assistive healthcare! Follow the project on Twitter <a href="" target="_blank"><b>@eu_harmony</b></a></li>
              <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Project Harmony is off to a fantastic start with our official Kick-off meeting today! So wonderful we could all come together from all over Europe (and the world!) <a href="https://twitter.com/hashtag/ProjectHarmony?src=hash&amp;ref_src=twsrc%5Etfw">#ProjectHarmony</a> <a href="https://twitter.com/hashtag/Robotics?src=hash&amp;ref_src=twsrc%5Etfw">#Robotics</a> <a href="https://twitter.com/hashtag/research?src=hash&amp;ref_src=twsrc%5Etfw">#research</a> <a href="https://twitter.com/ASL_ETHZ?ref_src=twsrc%5Etfw">@ASL_ETHZ</a> <a href="https://twitter.com/ETH_en?ref_src=twsrc%5Etfw">@ETH_en</a> <a href="https://twitter.com/rsiegwart?ref_src=twsrc%5Etfw">@rsiegwart</a> <a href="https://t.co/bL4rCFV6Uh">pic.twitter.com/bL4rCFV6Uh</a></p>&mdash; Harmony EU project (@eu_harmony) <a href="https://twitter.com/eu_harmony/status/1356661162851598337?ref_src=twsrc%5Etfw">February 2, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
              <li>Our paper on <a href="publications.html#Zhang2021"><b>Distributed Coverage Control using a Multi-robot System</b></a> was accepted to RAL!</li>
          </ul>
          </details>
          <details>
          <summary>2020</summary>
          <ul>
              <li>Our papers on <a href="publications.html#Breyer2020"><b>real-tme 6 DOF grasping in clutter</b></a>, <a href="publications.html#Achermann2020"><b>optical-thermal image alignment</b></a> and <a href="publications.html#Chen2020"><b>reinforcement learning for visual-inertial sensor calibration</b></a> will be presented at CORL 2020! Check out the papers available now in the <a href="publications.html"><b>publications</b></a> tab.</li>
              <li>Our IROS on demand video presentations are now available online!
                  <ul>
                  <li><a href="https://www.iros2020.org/ondemand/episode?id=1703&id2=Planning%20for%20Robot%20Interactions%20with%20Humans&1603699397340" target="_blank"><b>IAN: Multi-Behavior Navigation Planning for Robots in Real, Crowded Environments</b></a></li>
                  <li><a href="https://www.iros2020.org/ondemand/episode?id=2255&id2=Multi-Robot%20Systems%20-%20Learning&1603700086418" target="_blank"><b>With Whom to Communicate: Learning Efficient Communication for Multi-Robot Collision Avoidance</b></a></li>
                  <li><a href="https://www.iros2020.org/ondemand/episode?id=988&id2=Mapping%20for%20Navigation&1603700083004" target="_blank"><b>Accurate Mapping and Planning for Autonomous Racing</b></a></li>
                  </ul>
              </li>
              <li>Our papers on <a href="publications.html#Dugas2020"><b>interaction-aware motion planning</b></a>, <a href="publications.html#SerraGomez2020"><b>learning multi-robot communication policies</b></a> and <a href="publiations.html#Andresen2020"><b>autonomous racing</b></a> will be presented at IROS 2020! Check out the pre-prints available in the <a href="publications.html"><b>publications</b></a> tab.</li>
            <li>Check out our ICRA video presentation for <a href="https://www.youtube.com/watch?v=mstDjxxDFPc" target="_blank"><b>Informative path planning for active mapping under localization uncertainty</b></a></li>
            <li>Our papers on <a href="publications.html#Popovic2020b"><b>localisation-aware informative path planning</b></a> and <a href="publications.html#Zhang2020"><b>predicting communication connectivity for cooperative localisation</b></a> will be presented at ICRA 2020!</li>
            <li>Our JAAMAS paper on <a href="https://rdcu.be/b0BHL" target="_blank"><b>The impact of agent definitions and interactions on multiagent learning for coordination in traffic management domains</b></a> is now available online. Code for the multiagent learning experiments is also available <a href="code.html">[here]</a></li>
          </ul>
        </details>
        <details>
          <summary>2019</summary>
          <ul>
            <li>Check out our 2019 ASL Christmas video! (Short version and full version below)</li>
            <iframe width="400" height="225" src="https://www.youtube.com/embed/f8impUfin3Q" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <iframe width="400" height="225" src="https://www.youtube.com/embed/GvMKNSmOaGE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <li><a href="https://www.womenplusplus.ch" target="_blank"><b>Womenplusplus</b></a> are organising <a href="https://www.womenplusplus.ch/hacknlead" target="_blank"><b>Hack'n'Lead</b></a>, Switzerland's first women-friendly hack-a-thon! They're also hosting a series of workshops leading up to the event that you can sign up for <a href="https://www.womenplusplus.ch/prep" target="_blank">[here]</a>, with plenty of online material that you can try out for yourself.</li>
            <li>Our paper on <b>"Volumetric instance-aware semantic mapping and 3D object discovery"</b> was nominated for the IROS best paper award on Cognitive Robotics! Check out the paper <a href="publications.html">[here]</a>.</li>
            <li>My lecture on <b>"Learning to Coordinate"</b> is now available on the Multi-Robot Systems Summer School website. Follow the <a href="http://mrs.felk.cvut.cz/summer-school/" target="_blank">[link]</a> to see the recording and slides.</li>
            <li>Our <a href="https://n.ethz.ch/~chungj/WIPPAS2019/" target="_blank"><b>2nd Workshop on Informative Path Planning and Adaptive Sampling (WIPPAS 2019)</b></a> will be organized in conjunction with RSS 2019. The workshop will be held on Saturday, June 22, 2019. See you there!</li>
          </ul>
        </details>
        
        <details>
          <summary>2018</summary>
          <ul>
            <li>Check out our <a href="http://robotics.usc.edu/~wippas/" target="_blank"><b>Workshop on Informative Path Planning and Adaptive Sampling (WIPPAS 2018)</b></a> to be organized in conjunction with ICRA 2018. The workshop will be held on Monday, May 21, 2019. See you there!</li>
            <li>Our Special Issue on <a href="https://link.springer.com/journal/10514/42/4/page/1" target="_blank"><b>Online Decision-Making in Multi-Robot Coordination</b></a> is the April 2018 Issue of Autonomous Robots.</li>
          </ul>
        </details>
        </section>
        
        <section id="projects">
        <h2 align="left">Current and Past Projects</h2>
        
        <h3>ASL, ETH Z&uuml;rich</h3>
        <img class="myImages" id="mImg" src="Home/yumiBanana.png" height="256" hspace="10"
        alt="<b>Robotic Mobile Manipulation</b><p>Current robotic automation solutions typically offer 'islands of automation' where either mobility or manipulation is dealt with in isolation. Our research in this area aims to fill this gap in knowledge on combining both robotic mobility and manipulation modalities in complex, human-centred environments. Mobile manipulation tasks require robots that can interact with the world across a wide operational spectrum, from the (sub)millimetre precision required for fine manipulation to navigating across building- and campus-scale spaces. This motivates a holistic representation of the environment that facilitates the tight integration of socially aware planning, perception and control, and allows cognitive elements such as learning, reasoning and adaptation of actions for natural interaction.</p>"/>
        
        <img class="myImages" id="mImg" src="Home/navigation_in_crowds.png" height="256" hspace="10"
        alt="<b>Safe Robot Navigation in Dense Crowds</b><p>Navigating through human crowds is a tough challenge for a robot. Crowds can cause severe sensor occlusions and often don't leave much free space for the robot to move in, leading to what's known as the 'freezing robot problem'. As part of the European Commisssion H2020 CrowdBot Project, we are developing navigation and motion plannng algorithms that allow the robot to work with the flow of the crowd to get to its destination. We work on mapping, localisation, prediction, motion and interaction planning to help the robot answer four key questions for successful robot crowd navigation:</p><p>1. Where am I?</p><p>2. Who's around me?</p><p>3. Where am I going?</p><p>4. How should I get there?</p>"/>

        <h3>CoRIS, Oregon State University</h3>
        <img class="myImages" id="mImg" src="Home/NASAUTM.png" height="220" hspace="10"
        alt="<b>UAV Traffic Management</b><p>UAV traffic management in urban airspaces can be formulated as a problem of routing autonomously guided robots using cost space manipulation to induce safe trajectories in the work space. Each UAV does not explicitly coordinate with other vehicles in the airspace. Instead, they each execute their own individual internal cost-based planner to travel between locations. We are developing a high-level UAV traffic management (UTM) system that can dynamically adapt the cost space to reduce the number of conflict incidents in the airspace without needing explicit knowledge of the internal planners of each UAV. Our decentralized and distributed system of high-level traffic controllers each learn appropriate costing strategies via a neuro-evolutionary algorithm. The policies learned by our algorithm demonstrated a reduction in the total number of conflict incidents experienced in the airspace while maintaining throughput performance. Current research is looking at methods to account for traffic heterogeneity in the system.</p>"/>
        
        <img class="myImages" id="mImg" src="Home/probabilityOfImprovement.png" height="220" hspace="10"
        alt="<b>Risk Aware Graph Search</b><p>We are investigating novel approaches to searching a graph with probabilistic edge costs, namely, by incorporating available uncertainty information into the graph search. Our proposed risk aware graph search (RAGS) method consists of two major steps, the first is to perform an initial search across the graph to find the set of non-dominated paths. Following this, we perform risk-aware planning during path execution as information of the true neighboring edge costs become available. Initial results in a graph search domain have demonstrated superior performance when compared to A*, D* and a greedy approach.</p>"/>
        
        <img class="myImages" id="mImg" src="Home/structuralCreditAssignment.png" height="220" hspace="10"
        alt="<b>Structural Credit Assignment in Multiagent Policy Learning</b><p>Autonomous multi-robot teams can be used in complex tasks to improve performance in terms of both speed and effectiveness. However, use of multi-robot systems presents additional challenges. Specifically, in domains where the robots' actions are coupled, coordinating multiple robots to achieve cooperative behavior at the group level is difficult. Reward shaping can greatly benefit policy learning in multi-robot tasks and we are investigating various reward frameworks based on the idea of <i>counterfactuals</i> to tackle the structural credit assignment problem in these coupled domains.</p>"/>
        
        <BR CLEAR="left"/>
        <h3>ACFR, University of Sydney</h3>
        <img class="myImages" id="mImg" src="Home/FPtrial0eps50.png" height="256" hspace="10"
        alt="<b>Learning to Soar: Resource-Constrained Exploration</b><p>In 2014 I received my Ph.D., which I completed at the Australian Centre for Field Robotics at the University of Sydney. My research focused on the development of information-based exploration strategies that can be applied within reinforcement learning frameworks to characterise the exploration-exploitation trade-off within resource-constrained learning missions. The application of interest was an unpowered aerial glider learning to soar in a wind energy field.</p>"/>
        
        <img class="myImages" id="mImg" src="Home/locustTrials.png" height="256" hspace="10"
        alt="<b>Locust Swarm Tracking</b><p>The goal of this project was to gather intra-swarm locust motion data for biologists at the University of Sydney to study the effects of inter-locust interactions on the overall swarm motion. The Australian Centre for Field Robotics developed a system to collect this data consisting of micro retro-reflectors (to be attached to the insects) and a UAV equipped with a strobe beacon to autonomously fly loops over the swarm to track and monitor insect locations in real-time. Proof-of-concept was demonstrated in 2011.</p>"/>
        
        
        <div id="myModal" class="modal">
          
          <span class="close">&times;</span>
          <img class="modal-content" id="img01">
          <div id="caption"></div>
          
        </div>
        
<!--        <p><img src="Home/NASAUTM.png" align="left" height="256" hspace="10"/>-->
<!--        UAV traffic management in urban airspaces can be formulated as a problem of routing autonomously guided robots using cost space manipulation to induce safe trajectories in the work space. Each UAV does not explicitly coordinate with other vehicles in the airspace. Instead, they each execute their own individual internal cost-based planner to travel between locations. We are developing a high-level UAV traffic management (UTM) system that can dynamically adapt the cost space to reduce the number of conflict incidents in the airspace without needing explicit knowledge of the internal planners of each UAV. Our decentralized and distributed system of high-level traffic controllers each learn appropriate costing strategies via a neuro-evolutionary algorithm. The policies learned by our algorithm demonstrated a reduction in the total number of conflict incidents experienced in the airspace while maintaining throughput performance. Current research is looking at methods to account for traffic heterogeneity in the system.-->
<!--        </p>-->
        
<!--        <BR CLEAR="left"/>-->
<!--        <h3 align="left">Risk Aware Graph Search</h3>-->
<!--        <p><img src="Home/probabilityOfImprovement.png" align="right" height="256" hspace="10"/>-->
<!--        We are investigating novel approaches to searching a graph with probabilistic edge costs, namely, by incorporating available uncertainty information into the graph search. Our proposed risk aware graph search (RAGS) method consists of two major steps, the first is to perform an initial search across the graph to find the set of non-dominated paths. Following this, we perform risk-aware planning during path execution as information of the true neighboring edge costs become available. Initial results in a graph search domain have demonstrated superior performance when compared to A*, D* and a greedy approach.-->
<!--        </p>-->
        
<!--        <BR CLEAR="left"/>-->
<!--        <p><img src="Home/structuralCreditAssignment.png" align="left" height="256" hspace="10"/>-->
<!--        <h3 align="left">Structural Credit Assignment in Multiagent Policy Learning</h3>-->
<!--        Autonomous multi-robot teams can be used in complex tasks to improve performance in terms of both speed and effectiveness. However, use of multi-robot systems presents additional challenges. Specifically, in domains where the robots' actions are coupled, coordinating multiple robots to achieve cooperative behavior at the group level is difficult. Reward shaping can greatly benefit policy learning in multi-robot tasks and we are investigating various reward frameworks based on the idea of <i>counterfactuals</i> to tackle the structural credit assignment problem in these coupled domains.-->
<!--        </p>-->
        
<!--        <BR CLEAR="right"/>-->
<!--        <img src="Home/FPtrial0eps50.png" align="right" height="256" hspace="10"/>-->
<!--        <h3 align="left">Learning to Soar: Resource-Constrained Exploration</h3>-->
<!--        <p>-->
<!--            In 2014 I received my Ph.D., which I completed at the <a href="http://www.acfr.usyd.edu.au" target="_blank">Australian Centre for Field Robotics</a> at the University of Sydney. My research focused on the development of information-based exploration strategies that can be applied within reinforcement learning frameworks to characterise the exploration-exploitation trade-off within resource-constrained learning missions. The application of interest was an unpowered aerial glider learning to soar in a wind energy field.-->
<!--        </p>-->
        
<!--        <BR CLEAR="left"/>-->
<!--        <img src="Home/locustTrials.png" align="left" height="256" hspace="10"/>-->
<!--        <h3 align="left">Locust Swarm Tracking</h3>-->
<!--        <p>-->
<!--            The goal of this project was to gather intra-swarm locust motion data for biologists at the University of Sydney to study the effects of inter-locust interactions on the overall swarm motion. The Australian Centre for Field Robotics developed a system to collect this data consisting of micro retro-reflectors (to be attached to the insects) and a UAV equipped with a strobe beacon to autonomously fly loops over the swarm to track and monitor insect locations in real-time. Proof-of-concept was demonstrated in 2011.-->
<!--        </p>-->
        </section>
        <section>
        <p class="note" id="fn1" style="clear:left;"><a href="#r1">*</a> Going even further back, I completed my HSC at <a href="http://www.hurlstone.com.au" target="_blank">Hurlstone Agricultural High School</a> after graduating from <a href="http://www.sackvillst-p.schools.nsw.edu.au" target="_blank">Sackville Street Primary School</a>.
        </p>
        </section>
    </div>

    <div id="footer"></div>


<script type="text/javascript">
    $(document).ready(function(){
        $(".slide-toggle").click(function(){
            $(".box").animate({
                width: "toggle"
            });
        });
    });
</script>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    } 
  });
}
</script>

<script>
  // create references to the modal...
  var modal = document.getElementById('myModal');
  // to all images -- note I'm using a class!
  var images = document.getElementsByClassName('myImages');
  // the image in the modal
  var modalImg = document.getElementById("img01");
  // and the caption in the modal
  var captionText = document.getElementById("caption");

  // Go through all of the images with our custom class
  for (var i = 0; i < images.length; i++) {
    var img = images[i];
    // and attach our click listener for this image.
    img.onclick = function(evt) {
      modal.style.display = "block";
      modalImg.src = this.src;
      captionText.innerHTML = this.alt;
    }
  }

  var span = document.getElementsByClassName("close")[0];

  span.onclick = function() {
    modal.style.display = "none";
  }
</script>

    </body>
    <BR CLEAR="right"/>
</html>
